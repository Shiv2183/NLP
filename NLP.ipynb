{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shiv2183/NLP/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9VddoTeCmhU"
      },
      "source": [
        "# NLP\r\n",
        "\r\n",
        "The objective is:\r\n",
        "1. Understand the basic NLP algorithms\r\n",
        "2. Build the code base\r\n",
        "3. Use the understanding to buid application for Influencer Marketing Analytics.\r\n",
        "\r\n",
        "Corpus Creation\r\n",
        "1. Current corpus creation is from Amazon Electronics Reviews\r\n",
        "\r\n",
        "\r\n",
        "Future Work\r\n",
        "1. Speech to Text from Top N (N=5) youtube india influencers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKpRXHfYNpPh"
      },
      "source": [
        "# Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOGzjw9C6IUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f9db6f-04c8-4c83-d6bf-401c4d1fe59d"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "\r\n",
        "from time import sleep\r\n",
        "from tqdm import tqdm\r\n",
        "import string\r\n",
        "\r\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "Wwy1KOs_Nvho",
        "outputId": "311df5d8-77b0-4d9b-c560-c908ecb8a9b1"
      },
      "source": [
        "#----JSON Path\r\n",
        "electronics_path = \"https://www.cs.odu.edu/~hpendyal/courses/cs620/project/dataset/Electronics_5.json\"\r\n",
        "\r\n",
        "#---- Reading Electronics data\r\n",
        "print('-> Started Loading Data')\r\n",
        "Electronics = pd.read_json(electronics_path, lines=True)\r\n",
        "print('-> Total reviews : ',Electronics.reviewText.count())\r\n",
        "print(\"Data Loading completed in \")\r\n",
        "\r\n",
        "#----Check Data\r\n",
        "Electronics.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-> Started Loading Data\n",
            "-> Total reviews :  1689188\n",
            "Data Loading completed in \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AO94DHGC771SJ</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>amazdnu</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
              "      <td>5</td>\n",
              "      <td>Gotta have GPS!</td>\n",
              "      <td>1370131200</td>\n",
              "      <td>06 2, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AMO214LNFCEI4</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>[12, 15]</td>\n",
              "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
              "      <td>1</td>\n",
              "      <td>Very Disappointed</td>\n",
              "      <td>1290643200</td>\n",
              "      <td>11 25, 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A3N7T0DY83Y4IG</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>C. A. Freeman</td>\n",
              "      <td>[43, 45]</td>\n",
              "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
              "      <td>3</td>\n",
              "      <td>1st impression</td>\n",
              "      <td>1283990400</td>\n",
              "      <td>09 9, 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A1H8PY3QHMQQA0</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>Dave M. Shaw \"mack dave\"</td>\n",
              "      <td>[9, 10]</td>\n",
              "      <td>Not going to write a long review, even thought...</td>\n",
              "      <td>2</td>\n",
              "      <td>Great grafics, POOR GPS</td>\n",
              "      <td>1290556800</td>\n",
              "      <td>11 24, 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A24EV6RXELQZ63</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>Wayne Smith</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>I've had mine for a year and here's what we go...</td>\n",
              "      <td>1</td>\n",
              "      <td>Major issues, only excuses for support</td>\n",
              "      <td>1317254400</td>\n",
              "      <td>09 29, 2011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID        asin  ... unixReviewTime   reviewTime\n",
              "0   AO94DHGC771SJ  0528881469  ...     1370131200   06 2, 2013\n",
              "1   AMO214LNFCEI4  0528881469  ...     1290643200  11 25, 2010\n",
              "2  A3N7T0DY83Y4IG  0528881469  ...     1283990400   09 9, 2010\n",
              "3  A1H8PY3QHMQQA0  0528881469  ...     1290556800  11 24, 2010\n",
              "4  A24EV6RXELQZ63  0528881469  ...     1317254400  09 29, 2011\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdvte_NSOkE7"
      },
      "source": [
        "def clean_text(txt):\r\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\r\n",
        "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\r\n",
        "    return txt "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdGlcZTMFLWM",
        "outputId": "aad48157-3470-4702-aa11-3ad810ed7d04"
      },
      "source": [
        "#---- Creating Corpus\r\n",
        "n=100\r\n",
        "# Step 1 - Breaking each review in sentences.\r\n",
        "# Step 2 - Appending sentences to create a list of senteneces i.e. Corpus\r\n",
        "corpus =[]\r\n",
        "for review in tqdm(Electronics['reviewText'][:n]):\r\n",
        "  #review = clean_text(review)\r\n",
        "  sent_text = nltk.sent_tokenize(review)\r\n",
        "  #print(sent_text)\r\n",
        "  corpus = corpus + [clean_text(text) for text in sent_text]\r\n",
        "  #corpus = corpus + sent_text\r\n",
        "  sleep(5)\r\n",
        "print('-> Total length of sentences', len(corpus))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [08:20<00:00,  5.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-> Total lenngth of sentences 515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0KclcxoK50b",
        "outputId": "447fa612-7b5b-499c-c953-c7ebc5dcae7e"
      },
      "source": [
        "#----Check Corpus\r\n",
        "corpus[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['we got this gps for my husband who is an otr over the road trucker',\n",
              " 'very impressed with the shipping time it arrived a few days earlier than expected  within a week of use however it started freezing up could of just been a glitch in that unit',\n",
              " 'worked great when it worked',\n",
              " 'will work great for the normal person as well but does have the trucker option',\n",
              " 'the big truck routes  tells you when a scale is coming up ect  love the bigger screen the ease of use the ease of putting addresses into memory',\n",
              " 'nothing really bad to say about the unit with the exception of it freezing which is probably one in a million and thats just my luck',\n",
              " 'i contacted the seller and within minutes of my email i received a email back with instructions for an exchange',\n",
              " 'very impressed all the way around',\n",
              " 'im a professional otr truck driver and i bought a tnd 700 at a truck stop hoping to make my life easier',\n",
              " 'rand mcnally are you listeningfirst thing i did after charging it was connect it to my laptop and install the software and then attempt to update it']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JCH8CK_ezE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "209bcefa-9645-4bad-9bb4-c23eb0af573a"
      },
      "source": [
        "tokenizer = Tokenizer()\r\n",
        "\r\n",
        "def get_sequence_of_tokens(corpus):\r\n",
        "    ## tokenization\r\n",
        "    tokenizer.fit_on_texts(corpus)\r\n",
        "    total_words = len(tokenizer.word_index) + 1\r\n",
        "    \r\n",
        "    ## convert data to sequence of tokens \r\n",
        "    input_sequences = []\r\n",
        "    for line in tqdm(corpus):\r\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\r\n",
        "        for i in range(1, len(token_list)):\r\n",
        "            n_gram_sequence = token_list[:i+1]\r\n",
        "            input_sequences.append(n_gram_sequence)\r\n",
        "        sleep(5)\r\n",
        "    return input_sequences, total_words\r\n",
        "\r\n",
        "inp_sequences, total_words = get_sequence_of_tokens(corpus[:10])\r\n",
        "inp_sequences[:10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:50<00:00,  5.01s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[31, 32],\n",
              " [31, 32, 33],\n",
              " [31, 32, 33, 34],\n",
              " [31, 32, 33, 34, 9],\n",
              " [31, 32, 33, 34, 9, 5],\n",
              " [31, 32, 33, 34, 9, 5, 35],\n",
              " [31, 32, 33, 34, 9, 5, 35, 36],\n",
              " [31, 32, 33, 34, 9, 5, 35, 36, 10],\n",
              " [31, 32, 33, 34, 9, 5, 35, 36, 10, 13],\n",
              " [31, 32, 33, 34, 9, 5, 35, 36, 10, 13, 14]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJgm-L8DiDdP",
        "outputId": "e2b25fbb-aab7-4862-89ce-aa413c2193c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.texts_to_sequences(['I love you'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 70, 28]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRKvueCUQ99C"
      },
      "source": [
        "# Tutorial\r\n",
        "1. Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpaUTDJViYwU",
        "outputId": "31a4d8b4-bf27-4717-ffe5-343431d46256",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def get_sequence_of_tokens(corpus):\r\n",
        "    ## tokenization\r\n",
        "    tokenizer.fit_on_texts(corpus)\r\n",
        "    total_words = len(tokenizer.word_index) + 1\r\n",
        "    ## convert data to sequence of tokens \r\n",
        "    input_sequences = []\r\n",
        "    for line in tqdm(corpus):\r\n",
        "        input_sequences = input_sequences + (tokenizer.texts_to_sequences([line]))\r\n",
        "        sleep(5)\r\n",
        "    return input_sequences, total_words\r\n",
        "\r\n",
        "inp_sequences, total_words = get_sequence_of_tokens(corpus[:10])\r\n",
        "inp_sequences[:10]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:50<00:00,  5.01s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[31, 32, 33, 34, 9, 5, 35, 36, 10, 13, 14, 37, 1, 38, 15],\n",
              " [16,\n",
              "  17,\n",
              "  11,\n",
              "  1,\n",
              "  39,\n",
              "  40,\n",
              "  3,\n",
              "  41,\n",
              "  2,\n",
              "  42,\n",
              "  43,\n",
              "  44,\n",
              "  45,\n",
              "  46,\n",
              "  18,\n",
              "  2,\n",
              "  47,\n",
              "  4,\n",
              "  19,\n",
              "  48,\n",
              "  3,\n",
              "  49,\n",
              "  20,\n",
              "  21,\n",
              "  50,\n",
              "  4,\n",
              "  22,\n",
              "  51,\n",
              "  2,\n",
              "  52,\n",
              "  23,\n",
              "  53,\n",
              "  24],\n",
              " [25, 26, 27, 3, 25],\n",
              " [54, 55, 26, 9, 1, 56, 57, 58, 59, 60, 61, 62, 1, 15, 63],\n",
              " [1,\n",
              "  64,\n",
              "  12,\n",
              "  65,\n",
              "  66,\n",
              "  28,\n",
              "  27,\n",
              "  2,\n",
              "  67,\n",
              "  10,\n",
              "  68,\n",
              "  21,\n",
              "  69,\n",
              "  70,\n",
              "  1,\n",
              "  71,\n",
              "  72,\n",
              "  1,\n",
              "  29,\n",
              "  4,\n",
              "  19,\n",
              "  1,\n",
              "  29,\n",
              "  4,\n",
              "  73,\n",
              "  74,\n",
              "  75,\n",
              "  76],\n",
              " [77,\n",
              "  78,\n",
              "  79,\n",
              "  7,\n",
              "  80,\n",
              "  81,\n",
              "  1,\n",
              "  24,\n",
              "  11,\n",
              "  1,\n",
              "  82,\n",
              "  4,\n",
              "  3,\n",
              "  20,\n",
              "  83,\n",
              "  10,\n",
              "  84,\n",
              "  85,\n",
              "  23,\n",
              "  2,\n",
              "  86,\n",
              "  6,\n",
              "  87,\n",
              "  22,\n",
              "  5,\n",
              "  88],\n",
              " [8, 89, 1, 90, 6, 18, 91, 4, 5, 30, 8, 92, 2, 30, 93, 11, 94, 9, 13, 95],\n",
              " [16, 17, 96, 1, 97, 98],\n",
              " [99,\n",
              "  2,\n",
              "  100,\n",
              "  14,\n",
              "  12,\n",
              "  101,\n",
              "  6,\n",
              "  8,\n",
              "  102,\n",
              "  2,\n",
              "  103,\n",
              "  104,\n",
              "  105,\n",
              "  2,\n",
              "  12,\n",
              "  106,\n",
              "  107,\n",
              "  7,\n",
              "  108,\n",
              "  5,\n",
              "  109,\n",
              "  110],\n",
              " [111,\n",
              "  112,\n",
              "  113,\n",
              "  28,\n",
              "  114,\n",
              "  115,\n",
              "  8,\n",
              "  116,\n",
              "  117,\n",
              "  118,\n",
              "  3,\n",
              "  119,\n",
              "  120,\n",
              "  3,\n",
              "  7,\n",
              "  5,\n",
              "  121,\n",
              "  6,\n",
              "  122,\n",
              "  1,\n",
              "  123,\n",
              "  6,\n",
              "  124,\n",
              "  125,\n",
              "  7,\n",
              "  126,\n",
              "  3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxmjimy3u1W7"
      },
      "source": [
        "#Padding Text squeence\r\n",
        "import tensorflow as tf\r\n",
        "inp_sequences = tf.keras.preprocessing.sequence.pad_sequences(\r\n",
        "    inp_sequences, maxlen=27, dtype='int32', padding='pre', truncating='pre',\r\n",
        "    value=0.0\r\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkRk7wSCxweF",
        "outputId": "8240cdb9-a733-4f01-a04c-28f21d4d587e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inp_sequences"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31,\n",
              "         32,  33,  34,   9,   5,  35,  36,  10,  13,  14,  37,   1,  38,\n",
              "         15],\n",
              "       [  3,  41,   2,  42,  43,  44,  45,  46,  18,   2,  47,   4,  19,\n",
              "         48,   3,  49,  20,  21,  50,   4,  22,  51,   2,  52,  23,  53,\n",
              "         24],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,  25,  26,  27,   3,\n",
              "         25],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54,\n",
              "         55,  26,   9,   1,  56,  57,  58,  59,  60,  61,  62,   1,  15,\n",
              "         63],\n",
              "       [ 64,  12,  65,  66,  28,  27,   2,  67,  10,  68,  21,  69,  70,\n",
              "          1,  71,  72,   1,  29,   4,  19,   1,  29,   4,  73,  74,  75,\n",
              "         76],\n",
              "       [  0,  77,  78,  79,   7,  80,  81,   1,  24,  11,   1,  82,   4,\n",
              "          3,  20,  83,  10,  84,  85,  23,   2,  86,   6,  87,  22,   5,\n",
              "         88],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   8,  89,   1,  90,   6,  18,\n",
              "         91,   4,   5,  30,   8,  92,   2,  30,  93,  11,  94,   9,  13,\n",
              "         95],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,  16,  17,  96,   1,  97,\n",
              "         98],\n",
              "       [  0,   0,   0,   0,   0,  99,   2, 100,  14,  12, 101,   6,   8,\n",
              "        102,   2, 103, 104, 105,   2,  12, 106, 107,   7, 108,   5, 109,\n",
              "        110],\n",
              "       [111, 112, 113,  28, 114, 115,   8, 116, 117, 118,   3, 119, 120,\n",
              "          3,   7,   5, 121,   6, 122,   1, 123,   6, 124, 125,   7, 126,\n",
              "          3]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76uPo_nF7Rtu",
        "outputId": "917e3dbe-5a5f-4adc-874a-fb012e9ff66d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inp_sequences[6:10]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   8,  89,   1,  90,   6,  18,\n",
              "         91,   4,   5,  30,   8,  92,   2,  30,  93,  11,  94,   9,  13,\n",
              "         95],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,  16,  17,  96,   1,  97,\n",
              "         98],\n",
              "       [  0,   0,   0,   0,   0,  99,   2, 100,  14,  12, 101,   6,   8,\n",
              "        102,   2, 103, 104, 105,   2,  12, 106, 107,   7, 108,   5, 109,\n",
              "        110],\n",
              "       [111, 112, 113,  28, 114, 115,   8, 116, 117, 118,   3, 119, 120,\n",
              "          3,   7,   5, 121,   6, 122,   1, 123,   6, 124, 125,   7, 126,\n",
              "          3]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j8SNdqn7XwC",
        "outputId": "727cc41e-81bf-4c88-f287-6bb38b8216ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inp_sequences[0:5]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 31, 32, 33, 34,\n",
              "         9,  5, 35, 36, 10, 13, 14, 37,  1, 38, 15],\n",
              "       [ 3, 41,  2, 42, 43, 44, 45, 46, 18,  2, 47,  4, 19, 48,  3, 49,\n",
              "        20, 21, 50,  4, 22, 51,  2, 52, 23, 53, 24],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0, 25, 26, 27,  3, 25],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 54, 55, 26,  9,\n",
              "         1, 56, 57, 58, 59, 60, 61, 62,  1, 15, 63],\n",
              "       [64, 12, 65, 66, 28, 27,  2, 67, 10, 68, 21, 69, 70,  1, 71, 72,\n",
              "         1, 29,  4, 19,  1, 29,  4, 73, 74, 75, 76]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXTZMRuA4LWz",
        "outputId": "cae3c2ec-deec-4c0c-fb8f-afd8085fc031",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "total_words"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n0kJqDdkV-Z"
      },
      "source": [
        "#Declaring word embedding layer\r\n",
        "from tensorflow.keras.layers import Activation, Dense, Embedding, GlobalAveragePooling1D, Flatten\r\n",
        "embedding = Embedding(total_words, 100, input_length=inp_sequences.shape[1])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mj-t80EoXOC"
      },
      "source": [
        "#Creating sequential model\r\n",
        "from tensorflow.keras import Model, Sequential\r\n",
        "model = Sequential()\r\n",
        "model.add(embedding)\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    optimizer=\"adam\",\r\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n",
        "    metrics=[\"accuracy\"],\r\n",
        ")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME73v7z2yLBF",
        "outputId": "bbd4a52f-65c3-4d28-edc8-8ed902407021",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 27, 100)           12700     \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 2700)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 2701      \n",
            "=================================================================\n",
            "Total params: 15,401\n",
            "Trainable params: 15,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQV0OvICyH_M",
        "outputId": "2eb1b616-210b-4eab-bce3-68d171f7650f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "history = model.fit(\r\n",
        "    inp_sequences[6:10], epochs=1, validation_steps=20, validation_data=inp_sequences[0:5]\r\n",
        ")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-2cf78f8df025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minp_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1041\u001b[0m               (x, y, sample_weight), validation_split=validation_split))\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m       val_x, val_y, val_sample_weight = (\n\u001b[1;32m   1045\u001b[0m           data_adapter.unpack_x_y_sample_weight(validation_data))\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDJyCwvRNb0f"
      },
      "source": [
        "2. Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD_fhU5oNgCp"
      },
      "source": [
        "3. RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfhE8jbBNi5K"
      },
      "source": [
        "4. LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y7MBLIpsmhi"
      },
      "source": [
        "# Social Media Influencer Analytics\r\n",
        "# Objective 1 - Unstructured Data to Structured Data\r\n",
        "1. Convert speech to text. - \r\n",
        "a. converting sound to txt\r\n",
        "b. Entity Recognition for tagging\r\n",
        "2. Convert images to objects - Time in seconds an object is displayed in the video\r\n",
        "3. Positive/Negative Reviews - Entity Recognition\r\n",
        "\r\n",
        "#Objective 2 -Club data with youtube impressions data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-VrA0lEsllz"
      },
      "source": [
        ""
      ]
    }
  ]
}